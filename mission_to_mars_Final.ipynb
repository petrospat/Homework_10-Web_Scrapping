{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Use this file to complete all of your scraping and analysis tasks. The following outlines what you need to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_soup (url):\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "    # Retrieve page with the html module\n",
    "    html = browser.html\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = bs(html, 'html.parser')\n",
    "    browser.quit()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'https://mars.nasa.gov/news/'\n",
    "y = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "z = 'https://twitter.com/marswxreport?lang=en'\n",
    "w = 'https://space-facts.com/mars/'\n",
    "q = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Webscrap News\n",
    "\n",
    "soup = url_soup(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = soup.find_all('li', class_='slide')\n",
    "#initialize lists for use at python\n",
    "news_title = []\n",
    "news_description = []\n",
    "\n",
    "for result in results:\n",
    "    # Use Beautiful Soup's find() method to navigate and retrieve attributes    \n",
    "    \n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        title = result.find('h3').text\n",
    "        description = result.find('div', class_=\"article_teaser_body\").text\n",
    "        news_title.append(title)\n",
    "        news_description.append(description)\n",
    "        print(title)\n",
    "        print(description)\n",
    "        print('-----------')\n",
    "        \n",
    "    except SyntaxError as s:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscrap images\n",
    "\n",
    "soup = url_soup(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract featured image JPG id \n",
    "featured_image = soup.find('div', class_='carousel_container')\n",
    "link = featured_image.a['data-fancybox-href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image link buid up\n",
    "jpg_id = link.split(\"/mediumsize/\")[1].split(\"_ip\")[0]\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/'+ jpg_id +'_hires.jpg'\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscrap tweeter\n",
    "\n",
    "soup = url_soup(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of tweets with weather\n",
    "tlist = soup.find_all(\"li\", class_=\"js-stream-item\")\n",
    "wtext = None\n",
    "# Search through list for weather tweet/ skip retweets\n",
    "for t in tlist:\n",
    "    if t.div[\"data-screen-name\"] == \"MarsWxReport\":       \n",
    "        wtext = t.find(class_=\"tweet-text\").a.previousSibling \n",
    "#             if \"Sol\" in str(wtext):\n",
    "#                 wtext\n",
    "        break   \n",
    "wtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscrap MarsFacts\n",
    "\n",
    "soup = url_soup(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap html table into a dataframe and back to html\n",
    "tables = pd.read_html(w)\n",
    "df = tables[0]\n",
    "df.columns = ['property','fact']\n",
    "html_table = df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscrap Mars Hemispheres\n",
    "\n",
    "soup = url_soup(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract featured image JPG id \n",
    "get_headers = soup.find_all('div', class_='item')\n",
    "\n",
    "title = []\n",
    "img_url = []\n",
    "hemisphere_image_urls = {}\n",
    "\n",
    "for g in get_headers:\n",
    "    \n",
    "    t = g.find('h3').text\n",
    "    img_src = g.a['href']\n",
    "    img_src_sp = img_src.split(\"/search/map/\")[1]\n",
    "    f_img = 'https://astropedia.astrogeology.usgs.gov/download/' + img_src_sp + '.tif/full.jpg'\n",
    "    title.append(t)\n",
    "    img_url.append(f_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip lists, Transpose them and convert them into a list of Dictionaries\n",
    "hemisphere_image_urls  = []\n",
    "\n",
    "z = pd.DataFrame(list(zip(title,img_url)),columns =['title','img_url']).T.to_dict()\n",
    "\n",
    "for x in range(len(title)):\n",
    "    hemisphere_image_urls .append(z[x])\n",
    "\n",
    "hemisphere_image_urls   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_data = {}\n",
    "\n",
    "mars_data[\"Title\"] = news_title[0]\n",
    "mars_data[\"Description\"] = news_description[0]\n",
    "mars_data[\"Mars_Img\"] = featured_image_url\n",
    "mars_data[\"Weather\"] = wtext\n",
    "mars_data[\"Facts\"] = html_table\n",
    "mars_data[\"Hemispheres\"] = hemisphere_image_urls\n",
    "\n",
    "mars_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
